\section{Limitations and Future Directions}
\label{sec:discussion}


\noindent \textbf{Learning a predictive model vs learning the underlying structure.}
Building a causal performance model could be more expensive than performance influence models. The reason for having a potentially higher learning cost is that in addition to learning a predictive model, we also need to learn the structure of the input configuration space.
However, exploiting causal knowledge is more helpful in search-like tasks (e.g., performance optimization~\cite{JC:MASCOTS16,JVKS:FSE18}) that looks for %searching through the search space that finds 
higher quality samples, making it possible to debug or optimize with a few samples.

\noindent \textbf{Dealing with an incomplete causal model.} Existing off-the-shelf causal graph discovery algorithms like FCI remain ambiguous while data is insufficient and returns partially directed edges. For highly configurable systems, gathering high-quality data is challenging. To address this issue, we develop a novel pipeline for causal model discovery by combining FCI with entropic causality, an information-theoretic approach~\cite{Kocaoglu2017} to causality that takes the direction across which the entropy is lower as the causal direction. Such an approach helps to reduce ambiguity and thus allows the causal graph to converge faster. Note that estimating a theoretical guarantee for convergence is out of scope, as having a global view of the entire configuration space is infeasible. Moreover,  the presence of too many confounders can affect the correctness of the causal models, and this error may propagate along with the structure if the dimensionality is high. Therefore, we use a greedy refinement strategy to update the causal graph incrementally with more samples; at each step, the resultant graph can be approximate and incomplete, but asymptotically, it will be refined to its correct form given enough time and samples.

\noindent \textbf{Algorithmic innovations for faster convergence.} The efficacy of \ourapproach depends on several factors such as the representativeness of the observational data or the presence of unmeasured confounders that can negatively affect the quality of the causal model. There are instances where the causal model may be incorrect or lack some crucial connections that may result in detecting spurious root causes or recommending incorrect repairs. One promising direction to address this problem would be to develop new algorithms for Stage II \& III of \ourapproach (see Section~\ref{sec:methodology}). Specifically, we see the potential for developing innovative approaches for learning better structure, incorporating domain knowledge by restricting the structure of the underlying causal model. In addition, there are potentials for developing better sampling algorithms by either shrinking the search space (e.g., using transfer learning~\cite{JVKS:FSE18}) or searching the space more efficiently to determine effective interventions that enable faster convergence to the true underlying structure. 

\noindent \textbf{Incorporating domain knowledge.} Additionally, there is scope for developing new approaches for either automatically extracting constraints (e.g., from source code or other downstream artifacts) to incorporate in learning causal performance model or approaches to make humans part of the loop for correcting the causal performance model during learning. Specifically, new approaches could provide infrastructure as well as algorithms to determine when to ask for human feedback and what to ask for, e.g., feedback regarding a specific part of the causal model or feedback regarding the determined intervention at each step.

\noindent \textbf{Developing new domain-specific languages.} \ourapproach uses a query engine to translate common user queries into counterfactual statements. A domain-specific language to facilitate automated specification of queries from written unstructured data could potentially lead to the adoption of causal reasoning in the system development lifecycle. 